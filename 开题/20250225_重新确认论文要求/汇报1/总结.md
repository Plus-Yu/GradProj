#

## Efficient Fault Tolerance for Recommendation Model Training via Erasure Coding

本文聚焦于深度学习推荐模型（DLRM）训练中的容错问题，旨在解决现有容错方法的不足，具体体现在以下几个关键方面：

1. **节点故障影响训练完成**：DLRM训练通常在由数十或数百个节点组成的分布式系统中进行，由于嵌入表规模巨大，需占用大量节点内存。在这样的大规模系统里，节点故障频繁发生。一旦节点出现故障，就会导致模型参数丢失，若无法有效处理，训练任务将难以在规定的生产期限内完成，进而影响推荐模型的及时更新和应用。
2. **检查点机制的高开销问题**：检查点机制是目前DLRM训练中常用的容错手段，它通过定期暂停训练，将当前参数和优化器状态写入稳定存储。在正常操作时，写入检查点的过程会因DLRM的大尺寸而变得缓慢，导致训练频繁暂停，这增加了训练时间的开销。从故障中恢复时，系统需要回滚到最近的检查点，并重新执行故障发生前未完成的训练迭代，这不仅需要读取存储中的检查点，还会暂停新训练迭代的进行。随着DLRM模型规模不断增大，检查点的大小和写入、读取所需的时间也会增加，这些开销对训练的影响愈发严重。
3. **其他方法的局限性**：复制DLRM参数虽然能实现容错，但需要至少两倍于非复制系统的内存，考虑到DLRM的规模不断扩大，这种方法在实际应用中难以实施。而一些旨在减少检查点机制开销的技术，如近似检查点、异步检查点和日志记录等，也都存在各自的问题。近似检查点可能会改变模型的收敛性和最终准确性，引入不确定性，不利于生产环境中模型的调试；异步检查点会导致存储的模型状态不一致，影响恢复后模型的准确性；日志记录则因无法跟上梯度生成的速度，在DLRM训练中不可行。
4. **满足未来DLRM发展的需求**：随着DLRM规模持续增长，对容错机制的要求也越来越高。理想的容错方法应具备低训练时间和内存开销、快速从故障中恢复、不影响模型准确性且能良好地适应DLRM规模增长等特点。现有方法无法满足这些要求，因此需要一种新的容错方案，以支持未来DLRM的高效训练。 

为解决DLRM训练的容错问题，文章提出ECRec系统，综合运用纠删码和复制技术，结合多种策略提升容错能力和训练效率。

1. **混合冗余策略**：依据DLRM参数特性，对**嵌入表**及其优化器状态采用纠删码，对神经网络参数及其优化器状态进行复制。嵌入表内存占比大但梯度网络带宽占比小，神经网络参数则相反。纠删码嵌入表可降低内存开销，复制神经网络参数能减少网络带宽消耗，且不会大幅增加内存负担。
2. **正确更新冗余参数**
    - **嵌入表更新**：对嵌入表条目编码生成奇偶校验条目，用旋转奇偶校验放置法均衡服务器负载。针对状态ful优化器更新奇偶校验的难题，采用差异传播策略。服务器在应用梯度更新嵌入表条目和优化器状态后，将差异发送给奇偶校验服务器，确保奇偶校验条目正确更新。
    - **神经网络参数更新**：由于神经网络参数更新频繁、网络带宽消耗大，若用纠删码和差异传播会增加开销。因此，ECRec复制神经网络参数及其优化器状态，让梯度直接发送到持有副本的服务器进行本地更新，减少网络带宽开销。
3. **无暂停恢复机制**：基于纠删码特性，服务器故障时系统可继续训练。采用细粒度锁定技术，在恢复过程中，对要解码的丢失条目加锁，更新操作被缓冲，避免更新与恢复冲突。锁定粒度可依部署需求调整，在锁切换时间和服务器内存缓冲开销间平衡，确保训练在恢复时能高吞吐量持续进行。
4. **确保恢复一致性**：使用两阶段提交（2PC）协议，防止服务器故障时更新丢失导致模型不一致。训练迭代时，工人协调2PC过程，第一阶段计算并暂存参数更新，第二阶段统一应用更新。若第一阶段故障则中止重启，第二阶段故障则继续并等待非故障服务器确认，以此保证模型恢复前参数状态一致。

## CPR: UNDERSTANDING AND IMPROVING FAILURE TOLERANT TRAINING FOR DEEP LEARNING RECOMMENDATION WITH PARTIAL RECOVERY

这篇文章聚焦于深度学习推荐模型训练中的故障处理问题，旨在解决现有训练方式在面对节点故障时效率低、开销大以及模型精度受影响的难题。

**现有故障处理方法的不足**
    - **完全恢复的高开销**：在分布式模型训练中，常用的检查点机制（即完全恢复）虽能应对故障，但开销不可忽视。检查点相关开销平均占总训练时间的12%，严重时会使训练时间大幅延长，造成大量计算资源浪费。通过对17,000个训练作业分析发现，仅故障处理就耗费了1,156机器年的计算量。而且，不同训练作业的主要开销来源不同，优化某一项开销可能会增加其他开销，难以平衡。
    - **部分恢复的精度问题**：部分恢复作为替代方案，虽能减少计算损失，但会引入节点间状态不一致，导致模型质量下降。对于推荐模型训练，增加训练轮次也无法保证恢复模型精度，因为推荐模型容易过拟合。此外，部分恢复中检查点保存间隔对训练时间和模型精度的影响存在权衡关系，此前未得到充分研究。

**CPR系统的提出与目标**：为解决上述问题，文章提出CPR系统。其目标是通过**部分恢复**提高推荐模型训练的效率和可靠性，在降低训练时间的同时，保持模型精度在可接受范围内。具体通过三个关键方面实现：一是估计部分恢复的益处；二是选择合适的检查点保存间隔；三是优先保存更频繁访问参数的更新。

#

## Accelerating Communication in Deep Learning Recommendation Model Training with Dual-Level Adaptive Lossy Compression

DLRM 在工业领域广泛应用，但大规模训练时，其嵌入表规模庞大，导致多设备间的**全对全通信成为训练瓶颈**。现有解决方法如低比特量化和无损压缩存在局限性，而误差有界的有损压缩虽能实现更高压缩比，但在 DLRM 训练中应用面临挑战，如压缩比低、压缩开销大、误差传播影响模型精度等。

提出一种**专为 DLRM 数据设计的优化混合误差有界有损压缩算法，包括量化编码器和无损编码器**。针对 DLRM 数据特点，设计了基于向量的 LZ 编码和优化的熵编码，并通过离线分析选择更有效的编码器

## RecShard: Statistical Feature-Based Memory Optimization for Industry-Scale Neural Recommendation

#

## Pushing the Performance Envelope of DNN-based Recommendation Systems Inference on GPUs

DLRM 推理的性能瓶颈：DLRM 主要由嵌入、底部多层感知器（MLP）、特征交互和顶部 MLP 四个阶段组成。**其中，嵌入阶段由于频繁且不规则的内存访问，成为整个推理过程的主要瓶颈**。Embedding Bag 操作通过 CUDA 线程并行处理，每个线程处理部分嵌入向量，但该操作中的 gather - reduce 操作导致不规则内存访问，影响嵌入阶段性能。

提出软件预取和 L2 缓存固定等优化技术

## EVStore: Storage and Caching Capabilities for Scaling Embedding Tables in Deep Recommendation Systems

深度学习驱动的推荐系统依赖快速的模型推理，其中**嵌入向量（EV）表**用于将稀疏的分类数据转换为密集向量，是推荐系统的关键组件。然而，随着推荐模型规模扩大，EV 表尺寸呈指数增长，给内存管理带来巨大挑战。

提出了 EVStore，通过创新的三层缓存设计优化深度学习推荐系统中嵌入表的存储和查找性能，在减少延迟、提高吞吐量和降低内存使用方面成效显著

## Accelerating Personalized Recommendation with Cross-level Near-Memory Processing

深度学习推荐系统中，**嵌入层因存储需求大、计算强度低和内存访问模式不规则，成为系统性能瓶颈**，制约了推荐系统的发展

提出了一种跨级近内存处理（NMP）架构 ReCross，有效加速个性化推荐系统中的嵌入操作








